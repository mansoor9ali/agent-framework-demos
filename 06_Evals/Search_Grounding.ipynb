{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright 2025 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "tuOe1ymfHZPu"
   },
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_lgX9omPXF-"
   },
   "source": [
    "## Grounding using Search as a tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkR4fWudrHCs"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Search_Grounding.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDKKNfXWrHgs"
   },
   "source": [
    "In this notebook you will learn how to use the new Google Search tool available in the [Gemini](https://ai.google.dev/gemini-api/docs/models/gemini-v2) models, using both the unary API and the Multimodal Live API. Check out the docs to learn more about using [Search as a tool](https://ai.google.dev/gemini-api/docs/models/gemini-v2#search-tool).\n",
    "\n",
    "Note that the previous version of this guide using Gemini models priori to 2.0 and the legacy SDK can still be found [here](https://github.com/google-gemini/cookbook/blob/gemini-1.5-archive/quickstarts/Search_Grounding.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKu1tRBrQ7xj"
   },
   "source": [
    "## Set up the SDK and the client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIWKUlPqP5NK"
   },
   "source": [
    "### Install SDK\n",
    "\n",
    "This guide uses the [`google-genai`](https://pypi.org/project/google-genai) Python SDK to connect to the Gemini models.\n",
    "\n",
    "You'll find more details about the SDK on the [documentation](https://googleapis.github.io/python-genai/) or in the [Getting started](./Get_started.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6Fr84vJuPSHb"
   },
   "source": "# %pip install -q -U \"google-genai>=1.0.0\"",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a503bnWNQoCL"
   },
   "source": [
    "### Set up your API key\n",
    "\n",
    "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google-gemini/gemini-api-cookbook/blob/main/quickstarts/Authentication.ipynb) quickstart for an example."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RjvgYmdLQd5s"
   },
   "source": [
    "# import os\n",
    "# from google.colab import userdata\n",
    "#\n",
    "# os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhKXgMSNQrrV"
   },
   "source": [
    "### Select model and initialize SDK client\n",
    "\n",
    "The client will pick up your API key from the environment variable.\n",
    "\n",
    "Now select the model you want to use in this guide, either by selecting one in the list or writing it down. Keep in mind that some models, like the 2.5 ones are thinking models and thus take slightly more time to respond (cf. [thinking notebook](./Get_started_thinking.ipynb) for more details and in particular learn how to switch the thiking off)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C75s1LR9QmOz",
    "ExecuteTime": {
     "end_time": "2025-12-30T05:42:55.015728500Z",
     "start_time": "2025-12-30T05:42:53.813382800Z"
    }
   },
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client(\n",
    "        api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ") # the API is automatically loaded from the environement variable\n",
    "\n",
    "MODEL_ID = \"gemini-3-flash-preview\"\n",
    "#MODEL_ID = \"gemini-3-pro-preview\"\n",
    "# @param [\"gemini-2.5-flash-lite\", \"gemini-2.5-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash-preview\", \"gemini-3-pro-preview\"] {\"allow-input\":true, isTemplate: true}"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mDMScex1It5"
   },
   "source": [
    "## Use Google Search\n",
    "Search grounding is particularly useful for queries that require current information or external knowledge. Using Google Search, Gemini can access nearly real-time information and better responses."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FHIcazUO0-xU",
    "outputId": "dd7c97c2-4e72-433c-e274-6e1be9350f69",
    "ExecuteTime": {
     "end_time": "2025-12-30T05:41:29.120499500Z",
     "start_time": "2025-12-30T05:40:56.505680500Z"
    }
   },
   "source": [
    "from IPython.display import HTML, Markdown\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='What was the latest Indian Premier League match and who won?',\n",
    "    config={\"tools\": [{\"google_search\": {}}]},\n",
    ")\n",
    "\n",
    "# print the response\n",
    "display(Markdown(f\"Response:\\n {response.text}\"))\n",
    "# print the search details\n",
    "print(f\"Search Query: {response.candidates[0].grounding_metadata.web_search_queries}\")\n",
    "# urls used for grounding\n",
    "print(f\"Search Pages: {', '.join([site.web.title for site in response.candidates[0].grounding_metadata.grounding_chunks])}\")\n",
    "\n",
    "display(HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Response:\n Based on the current date of **December 30, 2025**, the latest Indian Premier League match was the **IPL 2025 Final**, played on **June 3, 2025**.\n\nIn that match, **Royal Challengers Bengaluru (RCB)** defeated **Punjab Kings (PBKS)** by **6 runs** to win their maiden IPL title.\n\n**Match Details:**\n*   **Date:** June 3, 2025\n*   **Venue:** Narendra Modi Stadium, Ahmedabad\n*   **Scores:**\n    *   **Royal Challengers Bengaluru:** 190/9 (20 overs)\n    *   **Punjab Kings:** 184/7 (20 overs)\n*   **Result:** RCB won by 6 runs.\n*   **Player of the Match:** Krunal Pandya (RCB)\n\nPrior to the final, the **2024** season was won by the **Kolkata Knight Riders**, who defeated Sunrisers Hyderabad in the final."
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Query: ['', 'IPL 2024 winner', 'IPL 2025 schedule and results', 'latest Indian Premier League match result']\n",
      "Search Pages: ndtv.com, wikipedia.org, crictracker.com, olympics.com, iplt20.com, wikipedia.org, flashscore.com, wikipedia.org, jagranjosh.com, youtube.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGTabzSZjzKqP4ofbxkIC94ESX9hUzpkbmV_ARa5d62eYTygIe7zocMu_8j-AkO-8qlFGN59r7yjZ7JSUG26rKbFoBX947Kitl9830w1UFdlq8Yt0lGPLiKnsrVbLShQhLkZ8tvli6unMDDFg5F6z1uvYF1iPVrw7Vm9VgxEhIm8_BGbcx0TgZ-4WjDWJjNMYjBiPNVGwHOR5tSRgewplVH\">IPL 2025 schedule and results</a>\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG6e3Qf3lPRe8Jsl8lhE9xMqCWOVEDoE8KnP5Z11lQoyH2WhBg3Ywv4wKBFADQJB_Zv5IrCeKVujEniDLNtF_DPmBF_EBWd_xk5LdS-QWsPpUW6Z3Yf8LdPMUkvnWZ8-1FVMin6ePhgsf3dZM5vmRfhBoR79EKHjyoTcIwrl6PKOhkAbqBRd75lPol_-TX_SBDytuAtAfc-JDWEpkvaWO-g7t8cmMB79HDcK_ay\">latest Indian Premier League match result</a>\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF2RFxFY7XxyRmL1Q-EG9U4_xdlpuFEe9_342RzKVRIqOsucWJ8wnIC2QvP73oZ0WiulVVH-gW6H2D09xbQXHEWOhZ-Tw_7Qvt7Q_m4QHZN7fzhgVTwJnAQrBYEMmNUMRz-r_5tbXhEcBHlaDlnQl6pcy4cpDLthDr4vXZQKjh86Ix1jOzCwgETylH45FKZZgawqw==\">IPL 2024 winner</a>\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wROLHEYLLBHX"
   },
   "source": [
    "The information provided may be outdated, as it is based on a knowledge cutoff. For the most current and authoritative details, please refer to the official [Model documentation](https://ai.google.dev/gemini-api/docs/models#gemini-2.5-pro), which includes the latest knowledge cutoff date.\n",
    "\n",
    "You can see that running the same prompt without search grounding gives you outdated information:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EdUkQ40cKaGX",
    "outputId": "afde972f-4823-406d-9840-d628a16e6bfc",
    "ExecuteTime": {
     "end_time": "2025-12-30T05:41:48.861887500Z",
     "start_time": "2025-12-30T05:41:38.193058Z"
    }
   },
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='What was the latest Indian Premier League match and who won?',\n",
    ")\n",
    "\n",
    "# print the response\n",
    "display(Markdown(response.text))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "The latest Indian Premier League match was **Qualifier 2**, played on **Friday, May 24, 2024**.\n\n*   **The Match:** Sunrisers Hyderabad (SRH) vs. Rajasthan Royals (RR)\n*   **The Winner:** **Sunrisers Hyderabad (SRH)**\n*   **The Result:** SRH won by **36 runs**.\n\n**Brief Summary:**\nBatting first, Sunrisers Hyderabad scored **175/9** (Heinrich Klaasen scored 50). In response, the Rajasthan Royals were restricted to **139/7** in their 20 overs, with SRH spinners Shahbaz Ahmed and Abhishek Sharma taking crucial wickets.\n\n**What's Next:**\nSunrisers Hyderabad will now face the Kolkata Knight Riders (KKR) in the **IPL Final** on Sunday, May 26, 2024."
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYGib8EySfBE"
   },
   "source": [
    "## Use search in chat\n",
    "\n",
    "Start by defining a helper function that you will use to display each part of the returned response."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "LUTX1SsKS3CE"
   },
   "source": [
    "# @title Define some helpers (run this cell)\n",
    "import json\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "\n",
    "def show_json(obj):\n",
    "  print(json.dumps(obj.model_dump(exclude_none=True), indent=2))\n",
    "\n",
    "def show_parts(r):\n",
    "  parts = r.candidates[0].content.parts\n",
    "  if parts is None:\n",
    "    finish_reason = r.candidates[0].finish_reason\n",
    "    print(f'{finish_reason=}')\n",
    "    return\n",
    "  for part in r.candidates[0].content.parts:\n",
    "    if part.text:\n",
    "      display(Markdown(part.text))\n",
    "    elif part.executable_code:\n",
    "      display(Markdown(f'```python\\n{part.executable_code.code}\\n```'))\n",
    "    else:\n",
    "      show_json(part)\n",
    "\n",
    "  grounding_metadata = r.candidates[0].grounding_metadata\n",
    "  if grounding_metadata and grounding_metadata.search_entry_point:\n",
    "    display(HTML(grounding_metadata.search_entry_point.rendered_content))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVlvJLcUTSuU"
   },
   "source": [
    "First try a query that needs realtime information, so you can see how the model performs _without_ Google Search."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qilzz3GKTdpl",
    "outputId": "ca0b0795-6261-46e6-a2e8-cd9393db14ae"
   },
   "source": [
    "chat = client.chats.create(model=MODEL_ID)\n",
    "\n",
    "response = chat.send_message('Who won the most recent Australia vs Chinese Taipei games?')\n",
    "\n",
    "show_parts(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svT-7wNdTCCj"
   },
   "source": [
    "Now set up a new chat session that uses the `google_search` tool.  The `show_parts` helper will display the text output as well as any Google Search queries used in the results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "St4MxVo2Sl6I",
    "outputId": "8e82f27b-41fc-4143-dc95-f8f21763a198"
   },
   "source": [
    "search_tool = {'google_search': {}}\n",
    "\n",
    "soccer_chat = client.chats.create(\n",
    "    model=MODEL_ID,\n",
    "    config={'tools': [search_tool]}\n",
    ")\n",
    "\n",
    "response = soccer_chat.send_message('Who won the most recent Australia vs Chinese Taipei games?')\n",
    "\n",
    "show_parts(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfkT7th0Tu1w"
   },
   "source": [
    "As you are using a `chat` session, you can ask the model follow-up questions too."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4L40g89mTyPs",
    "outputId": "17843e14-2273-4bc6-ac03-dcd35f8cafff"
   },
   "source": [
    "response = soccer_chat.send_message('Who scored the goals?')\n",
    "\n",
    "show_parts(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5liw_rs4T-gc"
   },
   "source": [
    "## Plot search results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VOKNOHLULMI"
   },
   "source": [
    "In this example you can see how to use the Google Search tool with code generation in order to plot results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "n00CHfm0UKp1",
    "outputId": "89fba644-4c0b-4a68-b06c-d5f9c5a7b9af"
   },
   "source": [
    "movie_chat = client.chats.create(\n",
    "    model=MODEL_ID,\n",
    "    config={'tools': [search_tool]}\n",
    ")\n",
    "\n",
    "response = movie_chat.send_message('Generate some Python code to plot the runtimes of the 10 more recent Denis Villeneuve movies.')\n",
    "\n",
    "show_parts(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JTk_5hnVw0r"
   },
   "source": [
    "First review the supplied code to make sure it does what you expect, then copy it here to try out the chart."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "42UTFDweVwNm",
    "outputId": "98985599-e34c-4027-cca8-426d000a9766"
   },
   "source": [
    "import re\n",
    "\n",
    "matchFound = re.search(r\"python\\n(.*?)```\", response.text, re.DOTALL)\n",
    "print(matchFound.group(1))\n",
    "if matchFound:\n",
    "  code = matchFound.group(1)\n",
    "  exec(code)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaMG2MmuWId3"
   },
   "source": [
    "One feature of using a chat conversation to do this is that you can now ask the model to make changes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K0vk3ol5WMvN",
    "outputId": "4076324c-0bce-4aa7-f14b-199097038eca"
   },
   "source": [
    "response = movie_chat.send_message('Looks great! Can you give the chart a dark theme instead?')\n",
    "\n",
    "show_parts(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16B0usiYaTBH"
   },
   "source": [
    "Again, always be sure to review code generated by the model before running it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vtfTv4ieFjYt",
    "outputId": "56668393-4028-4b7e-d2bc-9c31a5d79780"
   },
   "source": [
    "import re\n",
    "\n",
    "matchFound = re.search(r\"python\\n(.*?)```\", response.text, re.DOTALL)\n",
    "\n",
    "if matchFound:\n",
    "  code = matchFound.group(1)\n",
    "  exec(code)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUwwmbbRawwZ"
   },
   "source": [
    "## Use search in the Multimodal Live API\n",
    "\n",
    "The Search tool can be used in a live streaming context to have the model formulate grounded responses during the conversation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CUhcThmnK0mt"
   },
   "source": [
    "LIVE_MODEL_ID = 'gemini-2.5-flash-native-audio-preview-09-2025'  # @param ['gemini-2.0-flash-live-001', 'gemini-live-2.5-flash-preview', 'gemini-2.5-flash-native-audio-preview-09-2025'] {allow-input: true, isTemplate: true}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bax_JvhPdIry"
   },
   "source": [
    "### Define some helpers\n",
    "\n",
    "To use the bi-directional streaming API in Colab, you will buffer the audio stream. Define a `play_response` helper function to do the buffering, and once the audio for the current turn has completed, display an IPython audio widget.\n",
    "\n",
    "As each of the following examples only use a single prompt, also define a `run` helper to wrap the setup and prompt execution steps into a single function call. This helper takes a `config` argument that will be added to the `generation_config`, so that you can toggle the Search tool between examples."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "YEAdoUV2dH1o"
   },
   "source": [
    "# @title Helper functions for the Live API (run this cell)\n",
    "\n",
    "import asyncio\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import wave\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "DEFAULT_OUTPUT_RATE = 24000\n",
    "BASE_MODEL_CONFIG = {\n",
    "    # Here you can change the model's output mode between either audio or text.\n",
    "    # While this code expects an audio stream, text should work, but the stream\n",
    "    # may interleave with the `Buffering....` text.\n",
    "    'response_modalities': ['AUDIO']\n",
    "}\n",
    "\n",
    "async def play_response(stream):\n",
    "  \"\"\"Buffer audio output and display a widget. Returns the streamed responses.\"\"\"\n",
    "  turn_buf = io.BytesIO()\n",
    "  sample_rate = DEFAULT_OUTPUT_RATE\n",
    "\n",
    "  all_responses = []\n",
    "\n",
    "  print('Buffering', end='')\n",
    "  async for msg in stream.receive():\n",
    "    all_responses.append(msg)\n",
    "\n",
    "    if audio_data := msg.data:  # This is what triggers the warnings, use the full path to access the audio data\n",
    "      turn_buf.write(audio_data)\n",
    "      if m := re.search(\n",
    "          'rate=(?P<rate>\\d+)',\n",
    "          msg.server_content.model_turn.parts[0].inline_data.mime_type\n",
    "      ):\n",
    "            sample_rate = int(m.group('rate'))\n",
    "\n",
    "    elif tool_call := msg.tool_call:\n",
    "      # Handle tool-call requests. Here is where you would implement\n",
    "      # custom tool code, but for this example, all tools respond 'ok'.\n",
    "      for fc in tool_call.function_calls:\n",
    "        print('Tool call', end='')\n",
    "        tool_response = genai.types.LiveClientToolResponse(\n",
    "            function_responses=[genai.types.FunctionResponse(\n",
    "                name=fc.name,\n",
    "                id=fc.id,\n",
    "                response={'result': 'ok'},\n",
    "            )]\n",
    "        )\n",
    "        await stream.send(input=tool_response)\n",
    "\n",
    "    print('.', end='')\n",
    "\n",
    "  print()\n",
    "\n",
    "  # Play the audio\n",
    "  if turn_buf.tell():\n",
    "    audio = np.frombuffer(turn_buf.getvalue(), dtype=np.int16)\n",
    "    display(Audio(audio, autoplay=True, rate=sample_rate))\n",
    "  else:\n",
    "    print('No audio :(')\n",
    "    print(f'  {len(all_responses)=}')\n",
    "\n",
    "  return all_responses\n",
    "\n",
    "\n",
    "async def run(query, config=None):\n",
    "  # Add any tools or other generation config.\n",
    "  config = BASE_MODEL_CONFIG | (config or {})\n",
    "\n",
    "  # Establish a live session. While this context manager is active, the\n",
    "  # conversation will continue.\n",
    "  async with client.aio.live.connect(model=LIVE_MODEL_ID, config=config) as strm:\n",
    "\n",
    "    # Send the prompt.\n",
    "    await strm.send(input=query, end_of_turn=True)\n",
    "    # Handle the model response.\n",
    "    responses = await play_response(strm)\n",
    "\n",
    "    return responses"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMevh_9NodRJ"
   },
   "source": [
    "### Stream with the Search tool\n",
    "\n",
    "First, execute a query _without_ the Search tool to observe the model's response to a time-sensitive query.\n",
    "\n",
    "Note that the Multimodal Live API is a 2-way streaming API, but to simplify running in a notebook, each audio response is buffered and played once it has been fully streamed, so you will need to wait a few seconds before the response starts to play."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0wXCugI3eOtS",
    "outputId": "d610c8cc-c9d4-4e58-980f-3eb4ab500838"
   },
   "source": [
    "await run('Who won the skateboarding gold medals in the 2024 olympics?');"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evvh0DgdpSBV"
   },
   "source": [
    "Now re-run with the Search tool enabled."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HYGEtdjupXM7",
    "outputId": "d3abf034-84bc-48cc-bc68-43becb13b197"
   },
   "source": [
    "responses = await run('Who won the skateboarding gold medals in the 2024 olympics?', {'tools': [search_tool]})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_7R6nAMp9zf"
   },
   "source": [
    "If you wish to see the full output that was returned, you can enable `show_output` here and run this cell. It includes the complete audio binary data, so it is off by default."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_UUZ5V_Upzpm"
   },
   "source": [
    "show_output = False\n",
    "\n",
    "if show_output:\n",
    "  for msg in responses:\n",
    "    print(msg.model_dump(exclude_none=True))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtt8p612q5CT"
   },
   "source": [
    "### Search with custom tools\n",
    "\n",
    "In the Multimodal Live API, the Search tool can be used in conjunction with other tools, including function calls that you provide to the model.\n",
    "\n",
    "In this example, you define a function `set_climate` that takes 2 parameters, `mode` (`hot`, `cold`, etc) and `strength` (0-10), and ask the model to set the climate control based on the live weather in the location you specify."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7-nQ1Sp9yM33",
    "outputId": "b72db0e5-529a-40b9-f9d8-cc7f495293ec"
   },
   "source": [
    "set_climate_tool = {'function_declarations': [{\n",
    "    'name': 'set_climate',\n",
    "    'description': 'Switches the local climate control equipment to the specified parameters.',\n",
    "    'parameters': {\n",
    "      'type': 'OBJECT',\n",
    "      'properties': {\n",
    "        # Define the \"mode\" argument.\n",
    "        'mode': {\n",
    "            'type': 'STRING',\n",
    "            'enum': [\n",
    "              # Define the possible values for \"mode\".\n",
    "              \"hot\",\n",
    "              \"cold\",\n",
    "              \"fan\",\n",
    "              \"off\",\n",
    "            ],\n",
    "            'description': 'Mode for the climate unit - whether to heat, cool or just blow air.',\n",
    "        },\n",
    "        # Define the \"strength\" argument.\n",
    "        'strength': {\n",
    "            'type': 'INTEGER',\n",
    "            'description': 'Intensity of the climate to apply, 0-10 (0 is off, 10 is MAX).',\n",
    "        },\n",
    "      },\n",
    "    },\n",
    "  },\n",
    "]}\n",
    "\n",
    "search_tool = {'google_search': {}}\n",
    "\n",
    "tools = {'tools': [search_tool, set_climate_tool]}\n",
    "\n",
    "responses = await run(\"Look up the weather in Paris using search and set my climate control appropriately. I trust your judgement, so just do it.\", tools)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvZvdxr7oJ7i"
   },
   "source": [
    "Now inspect the `tool_call` response(s) you received during the conversation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZzZlE9IFnwpS",
    "outputId": "7184dc53-5b75-4788-e822-621274fce149"
   },
   "source": [
    "for r in responses:\n",
    "  if tool := r.tool_call:\n",
    "    for fn in tool.function_calls:\n",
    "      args = ', '.join(f'{k}={v}' for k, v in fn.args.items())\n",
    "      print(f'{fn.name}({args})  # id={fn.id}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOt32shZaEXj"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "<a name=\"next_steps\"></a>\n",
    "\n",
    "Search grounding is not the only way to ground your requests, you can also use Youtube links and URL context. Check the [Grounding](./Grounding.ipynb) guide for more info on those capabilities.\n",
    "\n",
    "* For more demos showcasing multi-tool use in the Multimodal Live API, check out the [Plotting and Mapping cookbook](../examples/LiveAPI_plotting_and_mapping.ipynb).\n",
    "* To get started with the Live API with the Python SDK, check out the [starter guide](./Get_started_LiveAPI.ipynb).\n",
    "* To learn more about tool use in the Live API, check out the [Live API Tool Use cookbook](./Get_started_LiveAPI_tools.ipynb).\n",
    "\n",
    "Also check the other Gemini advanced capabilities (like [spatial understanding](../quickstarts/Spatial_understanding.ipynb)) that you can find in the [Gemini Cookbook](https://github.com/google-gemini/cookbook/tree/main/gemini-2/)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Tce3stUlHN0L"
   ],
   "name": "Search_Grounding.ipynb",
   "toc_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
